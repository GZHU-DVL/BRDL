# Balanced Residual Distillation Learning for 3D Point Cloud Class-Incremental Semantic Segmentation

A python implement for BRDL based on PyTorch framework.

## 1. Setup
### Installation

- Create and activate the environment

	```shell
	conda create -n BRDL python=3.7
	conda activate BRDL
	```

- Install pytorch

	```shell
	conda install pytorch==1.9.1 torchvision==0.10.1 torchaudio==0.9.1 cudatoolkit=11.3 -c pytorch -c conda-forge
	```

- Install other dependencies

	```shell
	pip install tensorboard transforms3d h5py torch-cluster==1.5.9 scikit-learn 
	```

	

### Data preparation

- For S3DIS dataset

	1. Download [S3DIS Dataset Aligned Version 1.2](http://buildingparser.stanford.edu/dataset.html)ï¼Œdecompress and put the download files in the ./datasets/S3DIS/

	2. Process the raw data into `.npy` format files by running

		```shell
		python ./preprocess/collect_s3dis_data.py --data_path './datasets/S3DIS/Stanford3dDataset_v1.2_Aligned_Version'
		```

		The folder named `scenes` will be generated in `./datasets/S3DIS/` by default.

	3. Split the rooms into blocks by running:

		```shell
		python ./preprocess/room2blocks.py --data_path './datasets/S3DIS/scenes'
		```

		The folder named `blocks_bs1_s1` will be generated in `./datasets/S3DIS/` by default.

	

- For ScanNet dataset

	1. Download [ScanNet V2](http://www.scan-net.org/), put the download files (folder `scans` ) in the ./datasets/ScanNet/

	2. Process the raw data into `.npy` format files by running:

		```shell
		python ./preprocess/collect_scannet_data.py --data_path './datasets/ScanNet/scans'
		```

		The folder named `scenes` will be generated in `./datasets/ScanNet/` by default.

	3. Split the rooms into blocks by running:

		```shell
		python ./preprocess/room2blocks.py --data_path './datasets/ScanNet/scenes'
		```

		The folder named `blocks_bs1_s1` will be generated in `./datasets/ScanNet/` by default.

	

## 2. Quick Start

### Training
To train the model base on our BRDL framework, please fill the arguments below and run the following script:

```shell
CUDA_VISIBLE_DEVICES=$GPU_ID python main.py --phase increOurs --cvfold $SPLIT --tasks "${TASKS}" --base_model_checkpoint_path "${BASE_MODEL_PATH}" --pc_augm
```

### Evaluation
After training, you can run the following script for evaluation:

```shell
CUDA_VISIBLE_DEVICES=$GPU_ID python main.py --phase increeval --cvfold $SPLIT --tasks "${TASKS}" --base_model_checkpoint_path "${BASE_MODEL_PATH}"
```

